{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import fasttext\n",
    "import bz2\n",
    "import string\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've tried working with all 3,6 millions of reviews, then I tried working with 500k reviews, but my laptop does not have enough computational power, so I settled on working with 360k.\n",
    "\n",
    "Labels are evenly distributed in the set, so it won't be a problem, but accuracy might take a hit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bz2.BZ2File(\"train.ft.txt.bz2\")\n",
    "data = data.readlines()\n",
    "data = [x.decode('utf-8') for x in data]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = data[:360000]\n",
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.DataFrame(sample_data)\n",
    "sample_data.to_csv(\"sample_train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2', '__label__1'] are the labels or targets the model is predicting\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised('sample_train.txt',label_prefix='__label__', thread=4, epoch = 10)\n",
    "print(model.labels, 'are the labels or targets the model is predicting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data \n",
    "test = bz2.BZ2File(\"test.ft.txt.bz2\")\n",
    "test = test.readlines()\n",
    "test = [x.decode('utf-8') for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = test[:40000] \n",
    "len(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = [w.replace('__label__2 ', '') for w in sample_test]\n",
    "new = [w.replace('__label__1 ', '') for w in new]\n",
    "new = [w.replace('\\n', '') for w in new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in sample_test]\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8988120119772891\n"
     ]
    }
   ],
   "source": [
    "# run the accuracy measure. \n",
    "print(roc_auc_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively high result, but I've tried this with all 3,6 millions and the roc_auc was somewhere around 91%. But it wouldn't be logical to compare models that were trained on different scales of data, so I guess I'll have to sacrifice those 2% for getting any results from machine learning algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__1    180295\n",
       "__label__2    179705\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train.sample(n = 360000, random_state=123).reset_index(drop=True)\n",
    "train_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__1    20127\n",
       "__label__2    19873\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test.sample(n = 40000, random_state=123).reset_index(drop=True)\n",
    "test_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'__label__2': 1, '__label__1': 0}\n",
    "train_sample['label'] = train_sample['label'].map(labels).astype(int) # changed to make further calculations easier\n",
    "test_sample['label'] = test_sample['label'].map(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data): \n",
    "    \n",
    "    data = data.str.lower() # lower case\n",
    "     \n",
    "    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation))) # remove punctuation\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['clean'] = process_data(train_sample['review'])\n",
    "test_sample['clean'] = process_data(test_sample['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this movie sucks: This movie supposedly about ...</td>\n",
       "      <td>this movie sucks this movie supposedly about m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Good Entertainment: This program a well edited...</td>\n",
       "      <td>good entertainment this program a well edited ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the job: This hamper does the job in my k...</td>\n",
       "      <td>does the job this hamper does the job in my ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Buffett Mails it In: Being a huge Buffett fan,...</td>\n",
       "      <td>buffett mails it in being a huge buffett fan i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sharp as a razor... almost.: Wow! My replaceme...</td>\n",
       "      <td>sharp as a razor almost wow my replacement is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359995</th>\n",
       "      <td>1</td>\n",
       "      <td>A different perspective on an often portrayed ...</td>\n",
       "      <td>a different perspective on an often portrayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359996</th>\n",
       "      <td>1</td>\n",
       "      <td>What a tragic waste. She had my favourite sung...</td>\n",
       "      <td>what a tragic waste she had my favourite sungl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359997</th>\n",
       "      <td>0</td>\n",
       "      <td>Worst book ever, seriously. . .: First, the ra...</td>\n",
       "      <td>worst book ever seriously   first the rating i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359998</th>\n",
       "      <td>1</td>\n",
       "      <td>Great Bed Rail: This rail has worked perfectly...</td>\n",
       "      <td>great bed rail this rail has worked perfectly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359999</th>\n",
       "      <td>1</td>\n",
       "      <td>Everything it promises, and more!: As an avid ...</td>\n",
       "      <td>everything it promises and more as an avid fan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                             review  \\\n",
       "0           0  this movie sucks: This movie supposedly about ...   \n",
       "1           0  Good Entertainment: This program a well edited...   \n",
       "2           1  Does the job: This hamper does the job in my k...   \n",
       "3           0  Buffett Mails it In: Being a huge Buffett fan,...   \n",
       "4           1  Sharp as a razor... almost.: Wow! My replaceme...   \n",
       "...       ...                                                ...   \n",
       "359995      1  A different perspective on an often portrayed ...   \n",
       "359996      1  What a tragic waste. She had my favourite sung...   \n",
       "359997      0  Worst book ever, seriously. . .: First, the ra...   \n",
       "359998      1  Great Bed Rail: This rail has worked perfectly...   \n",
       "359999      1  Everything it promises, and more!: As an avid ...   \n",
       "\n",
       "                                                    clean  \n",
       "0       this movie sucks this movie supposedly about m...  \n",
       "1       good entertainment this program a well edited ...  \n",
       "2       does the job this hamper does the job in my ki...  \n",
       "3       buffett mails it in being a huge buffett fan i...  \n",
       "4       sharp as a razor almost wow my replacement is ...  \n",
       "...                                                   ...  \n",
       "359995  a different perspective on an often portrayed ...  \n",
       "359996  what a tragic waste she had my favourite sungl...  \n",
       "359997  worst book ever seriously   first the rating i...  \n",
       "359998  great bed rail this rail has worked perfectly ...  \n",
       "359999  everything it promises and more as an avid fan...  \n",
       "\n",
       "[360000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train_sample['clean'].values.tolist()\n",
    "test_list = test_sample['clean'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2500, stop_words=stopwords.words('english'))\n",
    "processed_train = vectorizer.fit_transform(train_list).toarray()\n",
    "processed_test = vectorizer.fit_transform(test_list).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = processed_train\n",
    "y_train = train_sample['label']\n",
    "X_test = processed_test\n",
    "y_test = test_sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.9, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1234, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGboost = XGBClassifier(n_jobs = 1, random_state=1234, learning_rate=0.9)\n",
    "XGboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37864685, 0.62135315],\n",
       "       [0.82208693, 0.17791308],\n",
       "       [0.995191  , 0.00480904],\n",
       "       ...,\n",
       "       [0.84900904, 0.15099095],\n",
       "       [0.2113288 , 0.7886712 ],\n",
       "       [0.54813254, 0.45186743]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGboost.predict_proba(X_test)\n",
    "\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_whole = xgb[:,1]>=0.4 # cut-off value\n",
    "\n",
    "# converting the results to integer type\n",
    "xgb_int=xgb_whole.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_new = xgb[:,1]>=0.4\n",
    "xgb_new_int = xgb_new.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_new_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "39995    0\n",
       "39996    1\n",
       "39997    0\n",
       "39998    0\n",
       "39999    1\n",
       "Name: label, Length: 40000, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5864640464465128\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, xgb_new_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both roc_auc and F1 scores are very low for this model. It might be because I didn't preprocess words (no lemmatization, no tokenization - but I've read that it's not recommended for sentiment analysis). Fasttext obviously gave higher results. \n",
    "\n",
    "For learning rate 0.1 - ROC_AUC - 58,22%\n",
    "For learning rate 0.9 - ROC_AUC - 58,64%\n",
    "\n",
    "I tried different cut-off values but the 0.4 one gave the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/muonneutrino/sentiment-analysis-with-amazon-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models, layers, optimizers\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_sample['review'], train_sample['label'], random_state=1234, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_sample['label']\n",
    "test_texts = test_sample['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FEATURES = 10000\n",
    "tokenizer = Tokenizer(num_words=FEATURES)\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
    "val_texts = tokenizer.texts_to_sequences(val_texts)\n",
    "test_texts = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
    "train_texts = pad_sequences(train_texts, maxlen=LENGTH)\n",
    "val_texts = pad_sequences(val_texts, maxlen=LENGTH)\n",
    "test_texts = pad_sequences(test_texts, maxlen=LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.asarray(val_labels)\n",
    "trains = np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(LENGTH,))\n",
    "embedding = layers.Embedding(FEATURES, 64)(input_layer)\n",
    "text_layer = layers.Conv1D(128, 3, activation='relu')(embedding)\n",
    "text_layer = layers.BatchNormalization()(text_layer)\n",
    "text_layer = layers.MaxPooling1D(3)(text_layer)\n",
    "text_layer = layers.Conv1D(128, 3, activation='relu')(text_layer)\n",
    "text_layer = layers.BatchNormalization()(text_layer)\n",
    "text_layer = layers.MaxPooling1D(3)(text_layer)\n",
    "text_layer = layers.Conv1D(128, 3, activation='relu')(text_layer)\n",
    "text_layer = layers.BatchNormalization()(text_layer)\n",
    "text_layer = layers.MaxPooling1D(3)(text_layer)\n",
    "text_layer = layers.Conv1D(128, 3, activation='relu')(text_layer)\n",
    "text_layer = layers.GlobalMaxPooling1D()(text_layer)\n",
    "text_layer = layers.Flatten()(text_layer)\n",
    "text_layer = layers.Dense(128, activation='relu')(text_layer)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(text_layer)\n",
    "model = models.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288000 samples, validate on 72000 samples\n",
      "Epoch 1/2\n",
      "288000/288000 [==============================] - 1872s 6ms/sample - loss: 0.2334 - binary_accuracy: 0.9031 - val_loss: 0.1797 - val_binary_accuracy: 0.9295\n",
      "Epoch 2/2\n",
      "288000/288000 [==============================] - 1863s 6ms/sample - loss: 0.1555 - binary_accuracy: 0.9415 - val_loss: 0.1866 - val_binary_accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a88383b10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_texts, \n",
    "    trains, \n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_data=(val_texts, vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.9808\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: {:0.4}'.format(roc_auc_score(test_labels, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with 16 layers gave the best results among 3 models. I first tried working with 64 neurons, which gave me ROC-AUC score of around 97%, and with 12 layers, which gave me around 96% ROC-AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose ROC-AUC score because it basically averages over all possiblt tresholds and it has F score values. Also, the dataset was balanced, so it too affected the choice of the metric.\n",
    "\n",
    "FastText score: 89.88%\n",
    "\n",
    "TFIDF + XGBoost score: 58.64% (yikes)\n",
    "\n",
    "CNN 1D score: 98%\n",
    "\n",
    "So, the neural network did the best job out of all three. Go neural networks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
